{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom imblearn.over_sampling import SMOTE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Desbalanceamento de Dados\n\n## Por que desbalanceamento é uma questão?","metadata":{}},{"cell_type":"markdown","source":"1) Problemas para definição e mensuração dos problemas.\n\n2) Complicações na separabilidade das classes.\n\n3) Diversas funções de custo consideram dados balanceados.","metadata":{}},{"cell_type":"markdown","source":"# 1) Definição e Mensuração","metadata":{"execution":{"iopub.status.busy":"2022-11-16T20:39:18.167501Z","iopub.execute_input":"2022-11-16T20:39:18.168298Z","iopub.status.idle":"2022-11-16T20:39:18.199562Z","shell.execute_reply.started":"2022-11-16T20:39:18.168130Z","shell.execute_reply":"2022-11-16T20:39:18.197857Z"}}},{"cell_type":"markdown","source":" Quais abordagens comuns para resolução?\n    \n## 1) Uso de métricas robustas\n- É bastante comum o uso de métricas de avaliação que sejam robustas, como o AUC, que é mais invariante a diferentes niveis de desbalanceamento do que outras métricas.\n\n- Essa abordagem é reutilizavel, fornecendo métricas que são diretamente interpretaveis mesmo ao ser aplicadas em problemas diferentes.\n\n- Essa abordagem em geral não incorpora a informação de diferentes custos dentro da classe minoritaria, o que pode fazer com que modelos subótimos tenham \"melhor performance\" do que outras abordagens mais eficientes.\n\n- Exemplos dessa situação são modelos com alta precisão em observações de baixo valor da classe majoritária, mas com precisão péssima nas observações mais relevantes.\n\n## 2) Construção de métricas especificas\n- Essa abordagem tem a vantagem de apresentar intepretabilidade mais granular e próxima dos custos reais do problema, pensando no uso do modelo para tomada de decisões.\n\n- Exige maior dispendio de tempo, maior conhecimento teórico e complexidade técnica para sua elaboração, do que a utilização de métricas robustas.\n\n- Sua estruturação não é reutilizavel, sendo necessário estabelecer uma nova métrica de avaliação para cada nova situação e tornando necessário novo alinhamento de como interpertar a métrica.\n\n## 3) Redefinição do problema.\n\n- Outra abordagem possivel é buscar transformar o problema em uma situação mais simples, redefinindo publico alvo e target da situação.\n\n- A forma mais comum é focar em um subconjunto dos dados menos afetado pelo desbalanceamento mas que mantenha interesse de solução, dado que esse subconjunto possa ser facilmente identificado.\n\n- Um exemplo seria uma doença rara, mas que acomete mais pessoas de maior idade, e alteração do publico alvo apenas para idosos. Ou então alteração de publico em um problema de Churn, quando uma parte significativa da volumetria se concentra em clientes novos, com menor volumetria.\n\n- Outra estrategia é agrupar casos similares, para tratar eles de forma conjunta e simplificar a situação (ex: sem tumor, tumor benigno, tumor maligno; no lugar de gravidade numérica medida para cada tumor) \n\n- Nesse caso, pode ocorrer que não existam critérios tão óbvios e objetivos para agrupamento das observações. \n\n- Um ponto de atenção é que essas abordagens simplificadas não são equivalentes as situações originais, o que implica em perda de volumetrias, granularidades nos resultados e outras desconsideração de questões que podem ter impacto prático. ","metadata":{"execution":{"iopub.status.busy":"2022-11-16T20:45:23.478983Z","iopub.execute_input":"2022-11-16T20:45:23.479405Z","iopub.status.idle":"2022-11-16T20:45:23.509514Z","shell.execute_reply.started":"2022-11-16T20:45:23.479363Z","shell.execute_reply":"2022-11-16T20:45:23.507249Z"}}},{"cell_type":"markdown","source":"\n# 2) Separabilidade das classes.\n    \n A definição de uma fronteira de decisão é um ponto fundamental para realizar a separações entre as classes de um problema.\n\nQuando temos uma classe com baixissima ocorrencia frente a outra, dois fenomenos importantes podem impactar a estimação da fronteira de decisão\n\n## 1) Poucas observações das classes minoritarias dificultam identificar suas regiões do espaço.2) A classe majoritaria pode \"contaminar\" a região do espaço ocupada pelas classes minoritarias. Exemplo\n\n#### Caso 1)\n- É possivel observar que vai se tornando mais dificil definir uma boa fronteira de decisão conforme reduzimos as observações da classe minoritaria.\n\n- Nesse exemplo, estamos observando uma situação em 2 dimensões, porem um destaque importante é que mesmo sem o problema de desbalanceamento, a definição de uma fronteira de decisão já é dificultada pela maldição da dimensionalidade. Isso implica que os dois problemas existem conjuntamente.\n\n#### Caso 2)\n- É comum que existam diferentes regiões do espaço, com probabilidade muito maior ou menor de encontrarmos observações de cada uma das classes.\n\n- Conforme aumentamos a quantidade total de amostras de uma classe , todas essas diferentes regiões tem um aumento de densidade, ou seja, passam a conter mais pontos.\n\n- Isso implica que algumas regiões, com baixa probabilidade mas que compartilham o espaço com a classe minoritária, passam a ser populadas incrementalmente pela classe majoritária, \"ocultando\" as observações minoritárias presentes nessas regiões.   \n ","metadata":{"execution":{"iopub.status.busy":"2022-11-16T20:45:56.030370Z","iopub.execute_input":"2022-11-16T20:45:56.030780Z","iopub.status.idle":"2022-11-16T20:45:56.042843Z","shell.execute_reply.started":"2022-11-16T20:45:56.030746Z","shell.execute_reply":"2022-11-16T20:45:56.041107Z"}}},{"cell_type":"code","source":"def ExemploProblemaSeparabilidade(quantidade_majoritaria, quantidade_minoritaria):\n    \n    def gauss_2d(mu, sigma, target):\n        x = np.random.normal(mu, sigma)\n        y = np.random.normal(mu, sigma)\n        return (x, y, target)\n\n    distribuicao_classe_0 = pd.DataFrame([gauss_2d(0, 3, 0) for i in range(0, quantidade_majoritaria)], columns = ['var1', 'var2', 'target'])\n    distribuicao_classe_1 = pd.DataFrame([gauss_2d(10, 2.5, 1) for i in range(0, quantidade_minoritaria)], columns = ['var1', 'var2', 'target'])\n\n    df_todas_classes = pd.concat([distribuicao_classe_0, distribuicao_classe_1])\n\n    return df_todas_classes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 4, figsize=(25, 8), sharey=True)\n\nfor i in range(0, 4):\n        \n        df_poucas_obs = ExemploProblemaSeparabilidade(1000, 3 * (10 ** i))\n        df_contaminacao = ExemploProblemaSeparabilidade(100 * (10 ** i), 100)\n        \n        sns.scatterplot(x = df_poucas_obs['var1'], y = df_poucas_obs['var2'], hue = df_poucas_obs['target'], ax = axes[0, 3 - i]);\n        sns.scatterplot(x = df_contaminacao['var1'], y = df_contaminacao['var2'], hue = df_contaminacao['target'], ax = axes[1, i]);  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Quais abordagens comuns para resolução?\n\n## 1) Abordagens por amostragem (Undersampling e OverSampling)\n\n- O principio das abordagens por amostragem se voltam para; 1) Diminuir a contaminação da classe majoritária na classe minoritária, ao diminuir a quantidade de observações majoritárias utilizadas; e 2) Aumentar a quantidade de amostras presentes da classe minoritária, de forma a facilitar definir sua região do espaço\n\n- Uma vantagem muito grande dessas abordagens é que elas são Agnosticas em relação aos Modelos, ou seja, podem ser feitas nos dados de maneira independente aos modelos que serão utilizados nas observações.\n\n- Outra vantagem é a simplicidade e facilidade com que as abordagens de amostragem conseguem ser feitas, o que não aumenta muito a complexidade geral dos projetos.\n\n- Um ponto de atenção importante é que essas abordagens costumam poder ser realizadas de diversas maneiras diferentes, não resolvendo magicamente o problema, dependendo de alguns pontos principais na forma feita, podem inclusive piorar a situação anterior se não forem bem feitas.\n\n## 2) Ensembles\n\n- A ideia aqui é a combinação de modelos, usando critérios especificos, de maneira com que o problema da separabilidade seja resolvido pelo conjunto dos modelos combinados.\n\n- Muitas vezes, consegue utilizar melhor as informações contidas nos dados originais do que as abordagens de amostragem.\n\n- Costumam ser simples de serem feitas, porem adicionam uma camada extra de complexidade ao ser necessário combinar diversos modelos para obter o resultado.\n\n- Em geral, as técnicas costumam poder ser aplicadas em diferentes tipos de modelos, porem é necessário mais ajustes do que nas abordagens por amostragem.\n\n## 3) Alterações nos algoritmos.\n- A abordagem mais complexa de todas indicadas acima, pois envolve mexer diretamente na forma de implementação de cada um dos modelos utilizados\n\n- Todas as alterações são dependentes do modelo, ou seja, ao serem realizadas em um tipo de modelo, não podem ser reaplicadas em modelos de outros tipos.\n\n- Tem a vantagem de manter a complexidade de apenas um modelo para solução, sem realizar nenhuma alteração na distribuição realmente existente dos dados pelas metodologias de amostragem, assim como sem adicionar camadas de complexidade adicionais por ensembles.\n     ","metadata":{}},{"cell_type":"markdown","source":"#  3) Funções de custo\n\n Funções de custo\n \n- Geralmente é estabelecido alguma dinamica interna nos algoritmos de Aprendizagem Estátistica / Machine Learning para que eles \"aprendam\" com as informações repassadas.\n\n- Essa dinamica interna costuma ser constituida por alguma função de custo, que é uma função que mensura internamente a performance do modelo, e alguma metodologia para atualização dos parametros, de maneira a melhorar a performance mensurada pela função de custo.\n\n\n- Exemplos de funções de custo é o Minimo Erro Quadrado para regressões lineares, Gini/Entropia para Arvores de decisão e LogLoss para Regressões Logisticas\n\n- Tirando o caso do Minimos Erros Quadraticos, é pouco comum que funções de custo sejam escolhidas como métricas de avaliação de algoritmos; assim como métricas mais comuns de avaliações sejam escolhidas para serem funções de custo. \n\n- O motivo disso é que as funções de custo costumam ser escolhidas por serem faceis/rapidas de serem calculadas e por existir alguma garantia de convergencia da atualização dos parametros para um ponto ótimo, mas não costumam ter boa interpretabilidade para tomadas de decisão.\n\n- Já as métricas de avaliação mais comumente utilizadas (accuracy, precision, recall, auc, ks, etc) costumam apresentar maior interpretabilidade para tomada de decisão e avaliação do algoritmo, porem não costumam apresentar garantias de convergencia ao usadas como função de custo ou são excessivamente custosas computacionalmente para serem usadas dessa maneira.\n\n- Dado esses pontos acima e a discussão sobre mensuração de problemas desbalanceadas, é bastante comum que as funções de custo tradicionais em que os algoritmos foram implantados sejam sensiveis a desbalanceamentos, ou seja, sejam afetadas negativamente em algum aspecto.\n\n- No caso das arvores de decisão em problemas desbalanceados, é possivel que splits com pior separabilidade entre as classes sejam escolhidos, por apresentarem melhor Gini/Entropia, ou seja, algumas quebras piores serem escolhidas frente a outras melhores disponiveis.\n\n- Já no caso da regressão lógistica, o desbalanceamento impacta a função de custo de forma que as probabilidades estimadas para classe minoritária possam ficar extremamente descalibradas, mesmo quando existe separabilidade linear entre as classes.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Quais abordagens comuns para resolução?\n\n## 1) Abordagens por amostragem (Undersampling e OverSampling)\n\n- Pontos já discutidos \n\n## 2) Alterações nas funções de custo dos algoritmos.\n\n- Abordagem é bastante complexa de ser implementada, exigindo profundo conhecimento de programação/matemática para começar a ser realizada.\n\n- Exige muito mais tempo para ser realizado.\n\n- Não é independente do algoritmo, ou seja, não pode ser reaplicado em diferentes algoritmos após ser realizada.\n","metadata":{}},{"cell_type":"code","source":"def ExemploProblemaFuncaoCusto(quantidade_majoritaria, quantidade_minoritaria):\n    \n    def gauss_2d(mu, sigma, target):\n        x = np.random.normal(mu, sigma)\n        y = np.random.normal(mu, sigma)\n        return (x, y, target)\n\n    distribuicao_classe_0 = pd.DataFrame([gauss_2d(0, 3, 0) for i in range(0, quantidade_majoritaria)], columns = ['var1', 'var2', 'target'])\n    distribuicao_classe_1 = pd.DataFrame([gauss_2d(10, 3, 1) for i in range(0, quantidade_minoritaria)], columns = ['var1', 'var2', 'target'])\n\n    df_todas_classes = pd.concat([distribuicao_classe_0, distribuicao_classe_1])\n\n    return df_todas_classes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Proporção Classe Minoritária X Classe Majoritária\n\n### 1) 5 / 1000","metadata":{}},{"cell_type":"code","source":"df_funcao_custo = ExemploProblemaFuncaoCusto(1000, 5)\n\nsns.scatterplot(x = df_funcao_custo['var1'], y = df_funcao_custo['var2'], hue = df_funcao_custo['target']);\n\n\nfrom sklearn.linear_model import LogisticRegression\n\nlreg = LogisticRegression()\n\nlreg.fit(df_funcao_custo[['var1', 'var2']], df_funcao_custo['target'])\n\ny_predicted = pd.Series(lreg.predict(df_funcao_custo[['var1', 'var2']]))\ny_predicted_proba = pd.DataFrame(lreg.predict_proba(df_funcao_custo[['var1', 'var2']]))[1]\n\ny_predicted_proba.tail().to_dict()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  2) 5 / 10000","metadata":{"execution":{"iopub.status.busy":"2022-11-16T20:49:13.814628Z","iopub.execute_input":"2022-11-16T20:49:13.815032Z","iopub.status.idle":"2022-11-16T20:49:13.820612Z","shell.execute_reply.started":"2022-11-16T20:49:13.815001Z","shell.execute_reply":"2022-11-16T20:49:13.818958Z"}}},{"cell_type":"code","source":"df_funcao_custo = ExemploProblemaFuncaoCusto(10000, 5)\n\nsns.scatterplot(x = df_funcao_custo['var1'], y = df_funcao_custo['var2'], hue = df_funcao_custo['target']);\n\n\nfrom sklearn.linear_model import LogisticRegression\n\nlreg = LogisticRegression()\n\nlreg.fit(df_funcao_custo[['var1', 'var2']], df_funcao_custo['target'])\n\ny_predicted = pd.Series(lreg.predict(df_funcao_custo[['var1', 'var2']]))\ny_predicted_proba = pd.DataFrame(lreg.predict_proba(df_funcao_custo[['var1', 'var2']]))[1]\n\ny_predicted_proba.tail().to_dict()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  3) 5 / 100000","metadata":{}},{"cell_type":"code","source":"df_funcao_custo = ExemploProblemaFuncaoCusto(100000, 5)\n\nsns.scatterplot(x = df_funcao_custo['var1'], y = df_funcao_custo['var2'], hue = df_funcao_custo['target']);\n\n\nfrom sklearn.linear_model import LogisticRegression\n\nlreg = LogisticRegression()\n\nlreg.fit(df_funcao_custo[['var1', 'var2']], df_funcao_custo['target'])\n\ny_predicted = pd.Series(lreg.predict(df_funcao_custo[['var1', 'var2']]))\ny_predicted_proba = pd.DataFrame(lreg.predict_proba(df_funcao_custo[['var1', 'var2']]))[1]\n\ny_predicted_proba.tail().to_dict()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Técnicas de Amostragem\n\n## Por que as técnicas de amostragem (undersampling e oversampling) costumam ser as mais conhecidas e utilizadas?\n\n- Simplicidade.\n- Facilidade.\n- Relativamente agnostico.\n- Possivel realizar de maneira modularizada, ou seja, independentemente do restante do pipeline e de modelo escolhido.\n\n## Quais são os problemas envolvidos nessas técnicas?\n\n#### 1) Se assume que essas abordagens são equivalentes as outras, porem não são.\n\n#### 2) Problema de UnderSampling\n\n- Joga fora observações que possivelmente são importantes para diferenciação entre as classes.\n\n#### 3) Problema do OverSampling\n\n- Por aumentar a quantidade de dados, aumenta a complexidade computacional para treinar o modelo.\n\n- Consegue apenas construir uma aproximação da distribuição original da classe minoritaria, não correspondendo com a distribuição verdadeira\n\n- Dependendo da forma, utiliza pressupostos diferentes que podem estar sendo violados (outliers/discretização/categoricas/proximidade com a fronteira de decisão)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T20:50:02.132544Z","iopub.execute_input":"2022-11-16T20:50:02.133004Z","iopub.status.idle":"2022-11-16T20:50:02.141663Z","shell.execute_reply.started":"2022-11-16T20:50:02.132964Z","shell.execute_reply":"2022-11-16T20:50:02.140264Z"}}},{"cell_type":"markdown","source":"##  Porque random Over e Under é um lixo?\n","metadata":{}},{"cell_type":"markdown","source":"- As técnicas de Random Over e Under sampling apresentam um deficiencia fundamental. Elas não utilizam nenhum critério para seleção das amostras removidas ou adicionadas.","metadata":{"execution":{"iopub.status.busy":"2022-11-16T20:50:22.016860Z","iopub.execute_input":"2022-11-16T20:50:22.017291Z","iopub.status.idle":"2022-11-16T20:50:22.024694Z","shell.execute_reply.started":"2022-11-16T20:50:22.017235Z","shell.execute_reply":"2022-11-16T20:50:22.023043Z"}}},{"cell_type":"markdown","source":"# Random UnderSampling\n\n- Nesse caso, isso significa que nenhum critério é aplicado para diferenciar entre amostras removidas - que podem ser tanto observações importantes para diferenciação entre as duas classes, observações muito distantes das fronteiras de decisão e que impactarão pouco no resultado ou então amostras que, de fato, contaminam a região do espaço ocupado pelas classes minoritarias.\n","metadata":{}},{"cell_type":"markdown","source":"# Random OverSampling\n\n- Nesse caso, são geradas diversas cópias da observações já existentes, sem nenhum critério para isso. Isso não implica que a região do espaço da classe minoritaria passou a ser melhor identificada, as observações copiadas podem estar longe da fronteira de decisão ou serem observações pouco representativas/ruidosas, prejudicando a classicação.\n\n ","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 4, figsize=(25, 8), sharey=True)\n\ndf_distro_real = ExemploProblemaSeparabilidade(10000, 500)\n\nsns.scatterplot(x = df_distro_real['var1'], y = df_distro_real['var2'], hue = df_distro_real['target'], ax = axes[0,0])\nsns.scatterplot(x = df_distro_real['var1'], y = df_distro_real['var2'], hue = df_distro_real['target'], ax = axes[1,0])\n\n\n###########\n\ndf = ExemploProblemaSeparabilidade(100, 5)\n\n\nfor i in range(1, 4):\n    \n    classe0_under = df.iloc[:-5].sample(n = 5)\n    classe1 = df.iloc[-5:]\n    df_undersampleado = pd.concat([classe0_under, classe1])\n\n    sns.scatterplot(x = df_undersampleado['var1'], y= df_undersampleado['var2'], hue = df_undersampleado['target'], ax = axes[0, i]);\n    sns.scatterplot(x = df['var1'], y= df['var2'], hue = df['target'], ax = axes[1, i]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Padrão na literatura de artigos produzidos sobre técnicas de amostragem para desbalanceamento\n\n\n- Oversampling costuma ter vantagem significa de performance sobre undersampling.\n\n- Quando testadas conjuntamente, um mix de OverSampling + Undersampling costuma obter melhor performance do que OverSampling puro.\n\n## Oversampling\n\nSMOTE surgiu rapidamente na literatura como uma das formas mais eficientes de amostragem, gerando diversas variações voltadas para superar suas variações.- Como Funciona?\nGera novas amostras a partir de extrapolação das antigas.\n\nOs passos são os seguintes: \n\n1) O algoritmo seleciona aleatoriamente uma observação.\n\n2) A partir dessa observação, encontra seus K vizinhos mais próximos (geralmente 5).\n\n3) Traça uma reta entre a primeira entre a primeira observação e cada um de seus K vizinhos.\n\n4) Em cada uma das K retas geradas, um ponto aleatório é selecionado e uma nova observação é gerada.\n\n5) Esse procedimento ocorre até o balanceamento **ou** outro critério de parada.\n- Quais os hyperparametros?\n1) Quantidade de K vizinhos escolhidos.\n\n2) Critério de parada.\n- Quais os pressupostos?\n1) Todas as variaveis são numéricas e continuas\n\n2) A distribuição da classe é convexa.\n\n3) É relativamente sensivel a outliers e amostras ruidosas da classe minoritária - relativamente devido a impacto de hyperparametros.\n\n4) Pode dar problema se classe for gerada por diversas distribuições, não interseccionais.\n Exem","metadata":{}},{"cell_type":"markdown","source":"# Exemplo - Variando K Vizinhos e Variando Critério de Parada\n","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 5, figsize=(25, 8), sharey=True)\n\nsns.scatterplot(x = df_distro_real['var1'], y = df_distro_real['var2'], hue = df_distro_real['target'], ax = axes[0, 0])\nsns.scatterplot(x = df_distro_real['var1'], y = df_distro_real['var2'], hue = df_distro_real['target'], ax = axes[1, 0])\n\n\nsns.scatterplot(x = df['var1'], y = df['var2'], hue = df['target'], ax = axes[0, 1])\nsns.scatterplot(x = df['var1'], y = df['var2'], hue = df['target'], ax = axes[1, 1])\n\n###########\n\nfor i in range(2, 5):\n    \n    sm = SMOTE(random_state = 42, k_neighbors = i - 1)\n    X_res, y_res = sm.fit_resample(df[['var1', 'var2']], df['target'])\n    \n    sm2 = SMOTE(random_state = 42, k_neighbors = 4, sampling_strategy = 1 / (5 - i))\n    X_res2, y_res2 = sm2.fit_resample(df[['var1', 'var2']], df['target'])    \n    \n    sns.scatterplot(x = X_res['var1'], y = X_res['var2'], hue = y_res.apply(lambda a : int(a)), ax = axes[0, i]);\n    sns.scatterplot(x = X_res2['var1'], y = X_res2['var2'], hue = y_res2.apply(lambda a : int(a)), ax = axes[1, i]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exemplo - Outlier","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 5, figsize=(30, 15), sharey=True)\n\ndfzao = ExemploProblemaSeparabilidade(300, 15)\nindice_outlier = dfzao.query('target == 0').sample(n = 1).index\ndfzao.loc[indice_outlier, 'target'] = 1\n\ndfzao2 = ExemploProblemaSeparabilidade(6000, 300)\n\nsns.scatterplot(x = dfzao2['var1'], y = dfzao2['var2'], hue = dfzao2['target'], ax = axes[0, 0]);\nsns.scatterplot(x = dfzao2['var1'], y = dfzao2['var2'], hue = dfzao2['target'], ax = axes[1, 0]);\nsns.scatterplot(x = dfzao2['var1'], y = dfzao2['var2'], hue = dfzao2['target'], ax = axes[2, 0]);\nsns.scatterplot(x = dfzao2['var1'], y = dfzao2['var2'], hue = dfzao2['target'], ax = axes[3, 0]);\nsns.scatterplot(x = dfzao2['var1'], y = dfzao2['var2'], hue = dfzao2['target'], ax = axes[4, 0]);\n\n\nfor k in range(0, 4):\n\n    for i in range(0, 5):\n\n        if k == 0:\n\n            sns.scatterplot(x = dfzao['var1'], y = dfzao['var2'], hue = dfzao['target'], ax = axes[i, k + 1]);\n            \n        else:\n            \n            sm = SMOTE(random_state = 42, k_neighbors = i + 1, sampling_strategy = 1 / (5 - k))\n            X_res, y_res = sm.fit_resample(dfzao[['var1', 'var2']], dfzao['target'])\n\n            sns.scatterplot(x = X_res['var1'], y = X_res['var2'], hue = y_res.apply(lambda a : int(a)), ax = axes[i, k + 1]);  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Métodos Popularizados e Mais Interessantes de UnderSampling\n\n- K Near Miss\n- Tomek Links\n- Edited Nearest Neighbours","metadata":{}}]}