{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-17T23:20:29.981282Z","iopub.execute_input":"2022-05-17T23:20:29.982001Z","iopub.status.idle":"2022-05-17T23:20:29.991095Z","shell.execute_reply.started":"2022-05-17T23:20:29.981952Z","shell.execute_reply":"2022-05-17T23:20:29.989884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.statespace.structural import UnobservedComponents\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nimport matplotlib.pyplot as plt\n\nfrom statsmodels.tsa.stattools import adfuller\n\nfrom sklearn import tree\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-05-17T23:20:31.96098Z","iopub.execute_input":"2022-05-17T23:20:31.961695Z","iopub.status.idle":"2022-05-17T23:20:33.655754Z","shell.execute_reply.started":"2022-05-17T23:20:31.961662Z","shell.execute_reply":"2022-05-17T23:20:33.654848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelos de Regressão aplicados em Séries Temporais\n\nComo regra geral, modelos tradicionais de regressão pressupoem que as a observações do problema são **Independentes e Identicamente distribuidas.**\n\nA **Independencia** afirma que a informação de uma amostra não fornece informações sobre outras amostras, enquanto a parte sobre **Identicamente Distribuidas** afirma que a distribuição das variaveis de entrada (ou independentes) e a distribuição da variavel de saida (ou dependente) são obtidas a partir de uma mesma distribuição para todas as observações.\n\n### **Sobre a independencia das observações**\n\n    É bastante comum que as amostras em séries temporais não sejam independentes e apresentem dependencia temporal, ou seja, que ao saber as caracteristicas de uma observação isso tambem fornece informação sobre outras observações da série temporal.\n    \n    Isso acontece por diversas razões. Por exemplo, em séries temporais ligadas a questões economicas, o efeito de questões como inflação, desemprego ou outras questões do cenário macroeconomico pode afetar os valores da série - com observações próximas no tempo compartilhando aproximadamente uma inflação/taxa de desemprego/variaveis macroeconomicas em comum, que variam de comportamento pelo restante da série.\n     \n    Essa violação no pressuposto da independencia, utilizado pelos modelos tradicionais de regressão, costuma enviesar as estimativas produzidas por modelos de regressão em séries temporais e gerar autocorrelação nos erros obtidos para observações próximas no tempo. \n    \n    Seguindo no exemplo de uma série temporal relacionada a questões economicas, dado um erro cometido pelo modelo no instante T, devido a inflação/desemprego/variaveis macroeconomicas, podemos supor que essa variaveis continuarão atuando sobre as observações do modelo em T+1 e portanto o erro em T+1 terá semelhanças com o erro em T.\n\n    Os modelos de séries temporais, por outro lado, costumam buscar modelar essas dependencia temporal, de forma com que a dependencia entre as observações possa ser quantificada e utilizada para gerar melhores estimativas sobre as observações futuras e comportamento geral da série.","metadata":{"execution":{"iopub.status.busy":"2022-02-21T20:15:29.59626Z","iopub.execute_input":"2022-02-21T20:15:29.59663Z","iopub.status.idle":"2022-02-21T20:15:29.609906Z","shell.execute_reply.started":"2022-02-21T20:15:29.596595Z","shell.execute_reply":"2022-02-21T20:15:29.608601Z"}}},{"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/daily-climate-time-series-data/DailyDelhiClimateTrain.csv')\ndf1['date'] = df1['date'].apply(lambda a : a.replace('-', ''))\ndf1['date'] = pd.to_datetime(df1['date'], format = '%Y%m%d')\n\ndf1 = df1.set_index('date')\n\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\n\nlin_reg.fit(X = df1[['humidity', 'wind_speed', 'meanpressure']].iloc[:1100],y = df1['meantemp'].iloc[:1100])\n\nforecast = lin_reg.predict(df1[['humidity', 'wind_speed', 'meanpressure']].iloc[1100:])\nforecast = pd.Series(forecast, index = df1.iloc[1100:].index)\n\nresidual = df1['meantemp'].iloc[1100:] - forecast","metadata":{"execution":{"iopub.status.busy":"2022-05-17T23:20:33.65769Z","iopub.execute_input":"2022-05-17T23:20:33.658019Z","iopub.status.idle":"2022-05-17T23:20:33.72096Z","shell.execute_reply.started":"2022-05-17T23:20:33.657974Z","shell.execute_reply":"2022-05-17T23:20:33.71988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Residuos Regressão Linear X Residuos UCM","metadata":{}},{"cell_type":"code","source":"# Residuos Regressão Linear\n\nplot_acf(residuo_consolidado.iloc[1:]);\n\nplot_pacf(residuo_consolidado.iloc[1:]);\n\n\n# Residuos UCM\n\nplot_acf(output_res.resid);\n\nplot_pacf(output_res.resid);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Sobre o carater identicamente distribuido das observações**   \n   \n   \n    Existem duas abordagens gerais de metodos de Machine Learning para os problemas de classificação/regressão. Uma das abordagens é utilizando metodologias parametricas, enquanto a outra utiliza metodologias não paramétricas.\n\n    As metodologias paramétricas assumem pressupostos fixos sobre qual é a função que consegue descrever a relação entre as variaveis independentes e dependentes. Por exemplo, uma regressão linear assume que uma reta consegue descrever a relação entre a variavel de entrada e saida, produzindo apenas essa forma de relação para relacionar essas informações.\n\n    Pressupostos simplificam o processo de aprendizagem, diminuindo a quantidade de observações necessárias para obter boas estimativas, mas tambem limitam as relações que podem ser estabelecidas entre Variaveis de Entrada e de Saida\n\n    Já os métodos não paramétricos não assumem uma forma de relação pré-definida para relação entre entrada/saida, conseguindo se adaptar a formas variadas, como relações não-lineares, interações entre variaveis, etc. São os tipos de algoritmos mais utilizados em ambientes de Big data, devido a essa maior flexibilidade permitir mais facilidade para obtenão de performances ótimas nas estimativas.\n\n    Embora os métodos não-parametricos em geral tenham maior performance, existem duas questões consideraveis que complicam sua utilização em séries temporais.\n\n    A primeira é que ao não presumir uma relação especifica entre as variaveis de entrada e saida, esses métodos não costumam apresentar capacidade de extrapolação para valores de entrada/saida que não estejam contidos dentro dos intervalos de treinamento.\n\n    Em problemas usuais de regressão, esse elemento pode apresentar inconvenientes ocasionais ao lidar com outliers. Porem ao lidar com séries temporais, esse elemento assume uma importancia fundamental, dado que é bastante comum que os valores entrada/saida de uma série temporal ocorram em intervalos não observados anteriormente. \n\n    Isso ocorre devido a tendencias de crescimento/decrescimento nos valores, assim como sazonalidades e periodos de ciclos de crescimento/decrescimento afetando os valores das observações.\n\n    A segunda questão é que métodos não paramétricos costumam exigir quantidades maiores de informações do que métodos paramétricos para estabelecer boas estimativas, o que usualmente é um problema em séries temporais.\n\n    Se um modelo de regressão for utilizado para um indicador gerado mensalmente, mesmo que esse indicador seja registrado por 10 anos, só teriamos 120 observações disponiveis para treino/teste/validação. \n\n    Mesmo se o indicador for gerado semanalmente, o salto no tamanho de amostras ainda não é enorme e conforme a granularidade aumenta, com indicadores gerados semanalmente/diariamente/horariamente, multiplas sazonalidades passam a poder impactar as observações (sazonalidade do dia da semana, semana do mês, mês do ano, hora do dia), se juntando na complicação anteriormente apresentada sobre extrapolação.\n ","metadata":{}},{"cell_type":"code","source":"profundidade = 3","metadata":{"execution":{"iopub.status.busy":"2022-05-17T23:21:09.605279Z","iopub.execute_input":"2022-05-17T23:21:09.605559Z","iopub.status.idle":"2022-05-17T23:21:09.610593Z","shell.execute_reply.started":"2022-05-17T23:21:09.605531Z","shell.execute_reply":"2022-05-17T23:21:09.609781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.linspace(1, 100, 1000)\n\ny = (x * 2) + 5\n\nx = x  + np.random.rand(1000) * 5\n\nregressor = tree.DecisionTreeRegressor(max_depth = profundidade)\n\nregressor.fit(x[:700].reshape(-1, 1), y[:700])\nprediction_train = regressor.predict(x[:700].reshape(-1, 1))\nprediction_test = regressor.predict(x[700:].reshape(-1, 1))\n\n\nfigure, axes = plt.subplots(ncols = 2, figsize = (15, 5))\n\nfigure.tight_layout()\n\n\n\nsns.scatterplot(x = x[:700], y = y[:700], ax = axes[0]);\nsns.scatterplot(x = x[:700], y = prediction_train, ax = axes[0]);\n\n\nsns.scatterplot(x = x[700:], y = y[700:], ax = axes[1]);\nsns.scatterplot(x = x[700:], y = prediction_test, ax = axes[1]);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-17T23:21:09.73155Z","iopub.execute_input":"2022-05-17T23:21:09.731973Z","iopub.status.idle":"2022-05-17T23:21:10.250709Z","shell.execute_reply.started":"2022-05-17T23:21:09.731937Z","shell.execute_reply":"2022-05-17T23:21:10.249801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Questões de Modelos de Séries Temporais\n\n\n### Séries Estacionárias\n\n    É bastante comum que modelos e técnicas voltados para séries temporais tenham como pressuposto que a série analisada seja **estacionária**, que significa que caracteristicas como a média e a variancia da séries são constantes pelo tempo.\n\n    A importancia disso vem do fato de que diversas propriedades validas para observações geradas de maneira **Independente e Identicamente Distribuida** tambem são válidos para **Processos Estacionários** em que as observações são geradas de maneira **Dependente** (dois exemplos importantes são a lei dos grandes numeros e o teorema do limite central).\n\n    Na realidade, é extremamente comum que as séries com que trabalhamos não sejam estacionárias e que sejam aplicadas transformações que as tornem estacionárias. A metodologia mais comum é a diferenciação da série, em que a cada valor Y da série momento t é subtraido do valor Y no momento t-1.\n\n    Essa transformação faz com que os valores da série original em T e T+1 sejam convertidos na variação de T para T+1 e T+1 para T+2. Isso costuma produzir séries estacionárias ao custo de perda de informação contida na série original, sobre os níveis anteriores em cada momento T e o quanto essa variação representa proporcionalmente ao nivel anterior.\n\n    Em situações em que toda ou quase toda informação está contina na variação entre cada momento no tempo, essa perda de informação tem pouco peso. Em situações em que o nivel anterior no momento T e a proporção de variação em relação ao nivel anterior importa, isso pode gerar impactos maiores sobre as estimativas. \n\n    Segue abaixo exemplo de situação em que a variação do valor 1 para 2, no instante T=0 para T = 1, é equivalente a variação de 100 para 101, no instante T = 12 para T = 13. Analogamente, a variação de 10 para 9, no instante T = 2 para T = 3, e a variação de 101 para 100, no instante T = 13 para T = 14, geram numeros equivalentes na série diferenciada.","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\nserie_original = pd.Series([1, 2, 10, 9, 15, 30, 25, 50, 72, 84, 75, 90, 100, 101, 100])\nserie_original.name = 'Serie Original'\n\nserie_diferenciada = serie_original.diff()\nserie_diferenciada.name = 'Serie Diferenciada'\n\nfigure, axes = plt.subplots(ncols=2, figsize=(15, 5))\naxes[0].plot(serie_original)\naxes[1].plot(serie_diferenciada)\nfigure.tight_layout()\n\npd.concat([serie_original , serie_diferenciada], axis = 1)\n\n\n#adfuller(serie_original.dropna())\n\n#adfuller(serie_diferenciada.dropna())","metadata":{"execution":{"iopub.status.busy":"2022-05-17T23:21:14.582053Z","iopub.execute_input":"2022-05-17T23:21:14.582721Z","iopub.status.idle":"2022-05-17T23:21:14.961823Z","shell.execute_reply.started":"2022-05-17T23:21:14.582671Z","shell.execute_reply":"2022-05-17T23:21:14.960964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Interpretabilidade e performance\n\nUm dos tipos de modelos mais utilizados devido a sua eficiencia e relativa simplicidade para construção são modelos **Autoregressivos (AR)**, que estima valores futuros a partir de uma combinação linear dos P valores anteriores, e modelos de **Médias Moveis (MA)**, em que os residuos dos ultimos Q pontos (obtidos pela diferença entre valor realizado e valor estimado) são ponderados.\n\nConforme são utilizados isoladamente e com ordem baixa nos valores de P e Q, esses modelos são consideravelmente interpretaveis; porem, conforme precisamos modelar séries mais elaboradas, a situação se complica de maneira bastante rápida ao exigir desde modelos ARIMA até SARIMAX.\n\nMesmo em casos de um ARIMA relativamente simples, o modelo já pode ser construido de maneira poquissimo intuitiva e hermética em relação a série original. Por exemplo, um modelo ARIMA (0,1,2) significa que os forecasts são gerados por uma média movel de ordem 2 dos residuos na série de diferenças, em relação aos valores originais.\n\nMesmo reformulando, para tentar aumentar a clareza, sobre o significado desse modelo ARIMA (0,1,2) uma dificuldade relativa se mantem para perceber quais relações diretas existem entre esse modelo e os valores da série original. Quando chegamos em situações com SARIMAX, essa questão já assume outro nivel na complexidade e perda de interpretabilidade/insight sobre a relação do modelo com os valores da série original.\n\nUm exemplo, um tanto próximo, seria a tentativa de apresentar de forma clara essa mesma relação ao utilizar um modelo SARIMAX (1,1,2)(1,1,0)12. O interessante de se notar é que embora esse modelo já tenha uma complexidade grande, a construção de uma série para qual ele seja necessário pode ser feita de maneira bastante simples.\n\nOs entraves e possibilidades relacionados a complexidade ou interpretabilidade dos modelos, fornecendo um insight sobre o comportamento da série original, dão ainda outro salto conforme se migra para o uso de redes neurais para estimação dessas séries.","metadata":{}},{"cell_type":"markdown","source":"## Unobserved Components Models\n\nUma abordagem bastante interessante para modelar séries temporais é a de **Unobserved Components Models**, que assume que poder modelar a série a partir da soma de diversos componentes, gerados de maneira a serem interpretaveis diretamente na relação com a série original.\n\n\\begin{equation}\ny_{t}=μ_{t}+γ_{t}+ψ_{t}+βX+ε_{t}\n\\end{equation}\n\nO primeiro componente é o **Nivel** da série, que pode ser entendido como o termo de intercepto correspondente a essa série temporal no instante T.\n\nComo parte desse componente, temos tambem a **Tendencia**, que é entendido como a dinamica de crescimento/decrescimento no **Nível** da série a cada nova movimentação de T para T+1.\n\n\\begin{equation}\nY_{t}=a_{t-1}+b_{t-1}+σ_{t-1}\n\\end{equation}\n\n\\begin{equation}\nb_{t}=b_{t-1}+ξ_{t-1}\n\\end{equation}\n\n\nO segundo termo é a **Sazonalidade**, que é entendido como um componente com periodicidade definida, em que a influencia de cada estação no valor da série soma zero ao considerarmos todas estações em um ciclo completo de sazonalidade - é possivel que multiplas sazonalidades (diaria, semanal, mensal, anual, etc) componham esse componente.\n\nO terceiro termo é o **Ciclo**, que é entendido como um componente voltado a capturar ciclos que impactem na série tenham periodicidade não tão rigidamente definida quanto as obtidas sazonalmente.\n\nO quarto termo são os **Regressores Externos**, que são entendidas como variaveis externas a série, que são utilizadas para sua estimação.\n\nO quinto termo é o **Residuo**, que pode ser construido a partir da correlação do erro em T+1 com o erro em T ou então apenas utilizando a diferença entre os valores realizados e estimados, independentemente em cada momento da série, durante sua modelagem.\n\n- A manipulação dos componentes acima fornece insight sobre a série e informação para Analise Exploratória da série temporal, assim como permite adicionar conhecimento externo a partir de priors para modelagem do problema.\n\n- A flexibilidade do modelo permite que cada um dos termos acima seja adicionado ou não de maneira independente, com cada um podendo ser estimado de maneira puramente deterministica ou então junto a um comportamento estocastico, que permite a evolução do comportamento do componente no tempo.\n\n- A flexiblidade dos componentes que compoe a série + seu carater deterministico/estocastico permitem a simplificação ou a complexificação do modelo ao lidar com diferentes séries temporais. O uso de mais termos e seu carater estocastico possibilita a construção de modelos mais complexo, em que seus diversos componentes evoluam no tempo e acompanham a dinamica da série; assim como os modelos podem ser construidos de maneira bastante parcimoniosa e regularizada ao lidar com séries curtas/simples, com poucos componentes sendo utilizados nessa modelagem e com comportamentos mais fixados.\n\n- Por um lado, isso permite que o modelo ganhe performance ao modelar séries longas, o que não necessariamente ocorre em outros modelos de séries tempories temporais que não adquirem mais ganho conforme avançados para alem de séries curtas/médias; por outro lado, cada componente permite ter sua significancia estatistica testada, o que é uma caracteristica relativamente importante ao lidar com séries com poucas observações.\n\n- Dados esses diversos componentes e sua capacidade de ovolução pelo tempo, o modelo é estruturado de maneira a modelar diretamente o comportamento de **processos não estacionarios**, sem a necessidade de transformação da série original e estacionarização para isso.","metadata":{}},{"cell_type":"markdown","source":"# Na prática","metadata":{}},{"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/daily-climate-time-series-data/DailyDelhiClimateTrain.csv')\ndf1['date'] = df1['date'].apply(lambda a : a.replace('-', ''))\ndf1['date'] = pd.to_datetime(df1['date'], format = '%Y%m%d')\n\ndf1 = df1.set_index('date')\n\nprint('Formato do dataframe é : ' + str(df1.shape))\ndf1.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T23:21:19.783961Z","iopub.execute_input":"2022-05-17T23:21:19.784551Z","iopub.status.idle":"2022-05-17T23:21:19.815541Z","shell.execute_reply.started":"2022-05-17T23:21:19.784498Z","shell.execute_reply":"2022-05-17T23:21:19.814633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['meantemp'].plot();","metadata":{"execution":{"iopub.status.busy":"2022-05-17T23:21:23.270178Z","iopub.execute_input":"2022-05-17T23:21:23.270479Z","iopub.status.idle":"2022-05-17T23:21:23.549802Z","shell.execute_reply.started":"2022-05-17T23:21:23.270444Z","shell.execute_reply":"2022-05-17T23:21:23.549223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model = {\n\n'level' : True,\n'stochastic_level' : False,\n    \n'trend' : False,\n'stochastic_trend' : False,\n    \n'seasonal' : None, #numerico indicando qual a sazonalidade\n'freq_seasonal' : [{'period' : 364,\n                   'harmonics' : 1}],\n'stochastic_seasonal' : False,\n'stochastic_freq_seasonal' : None,\n    \n'cycle' : False,\n'stochastic_cycle' : False,\n'damped_cycle' : False,\n'cycle_period_bounds' : None,\n    \n'irregular' : 0,\n'autoregressive' : 2 #Numero indicando ordem autoregressiva no erro\n    \n}\n\nucm = UnobservedComponents(df1['meantemp'].iloc[:1100], **model, exog = df1[['humidity', 'wind_speed']].iloc[:1100])\nucm_fitted = ucm.fit(method = 'powell', disp = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T22:02:15.36405Z","iopub.execute_input":"2022-02-21T22:02:15.364996Z","iopub.status.idle":"2022-02-21T22:02:16.348368Z","shell.execute_reply.started":"2022-02-21T22:02:15.36494Z","shell.execute_reply":"2022-02-21T22:02:16.346964Z"}}},{"cell_type":"code","source":"model = {\n\n'level' : True,\n'stochastic_level' : False,\n    \n'trend' : False,\n'stochastic_trend' : False,\n    \n'seasonal' : None, #numerico indicando qual a sazonalidade\n'freq_seasonal' : [{'period' : 364,\n                   'harmonics' : 1},\n                   {'period' : 29,\n                   'harmonics' : 1}\n                  ],\n'stochastic_seasonal' : False,\n'stochastic_freq_seasonal' : None,\n    \n'cycle' : False,\n'stochastic_cycle' : False,\n'damped_cycle' : False,\n'cycle_period_bounds' : None,\n    \n'irregular' : 0,\n'autoregressive' : 2 #Numero indicando ordem autoregressiva no erro\n    \n}\n\nucm = UnobservedComponents(df1['meantemp'].iloc[:1100], **model, exog = df1[['humidity', 'wind_speed']].iloc[:1100])\nucm_fitted = ucm.fit(method = 'powell', disp = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:27:43.438768Z","iopub.execute_input":"2022-05-21T19:27:43.439223Z","iopub.status.idle":"2022-05-21T19:27:43.526722Z","shell.execute_reply.started":"2022-05-21T19:27:43.439061Z","shell.execute_reply":"2022-05-21T19:27:43.525331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Resultados UCM | In Sample - One Step Ahead')\n\nprint('\\n')\nprint('RMSE : ' + str(np.sqrt(ucm_fitted.mse)))\nprint('MAE : ' + str(ucm_fitted.mae))\nprint('\\n')\n\nucm_fitted.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T23:23:53.138404Z","iopub.execute_input":"2022-05-17T23:23:53.13875Z","iopub.status.idle":"2022-05-17T23:23:53.162857Z","shell.execute_reply.started":"2022-05-17T23:23:53.138695Z","shell.execute_reply":"2022-05-17T23:23:53.161947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ucm_fitted.plot_components(figsize = (15, 15));","metadata":{"execution":{"iopub.status.busy":"2022-05-17T23:23:53.653957Z","iopub.execute_input":"2022-05-17T23:23:53.654616Z","iopub.status.idle":"2022-05-17T23:23:54.740783Z","shell.execute_reply.started":"2022-05-17T23:23:53.654549Z","shell.execute_reply":"2022-05-17T23:23:54.739776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ucm_fitted.plot_diagnostics(figsize = (20,10));","metadata":{"execution":{"iopub.status.busy":"2022-05-17T23:23:54.742344Z","iopub.execute_input":"2022-05-17T23:23:54.7426Z","iopub.status.idle":"2022-05-17T23:23:55.557161Z","shell.execute_reply.started":"2022-05-17T23:23:54.742565Z","shell.execute_reply":"2022-05-17T23:23:55.556012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"residuals = ucm_fitted.resid\nresiduals.name = 'residuals'\n\ndf1.join(residuals)[['meantemp', 'humidity', 'wind_speed', 'meanpressure', 'residuals']].corr()['residuals']","metadata":{"execution":{"iopub.status.busy":"2022-05-17T23:23:55.558775Z","iopub.execute_input":"2022-05-17T23:23:55.559268Z","iopub.status.idle":"2022-05-17T23:23:55.57297Z","shell.execute_reply.started":"2022-05-17T23:23:55.559219Z","shell.execute_reply":"2022-05-17T23:23:55.571953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"  ","metadata":{}},{"cell_type":"markdown","source":"# Performance UCM - Validação","metadata":{}},{"cell_type":"code","source":"predictions = df1['meantemp'].iloc[:1100]\n\nfor i in range(1100, 1462):\n\n    ucm = UnobservedComponents(df1['meantemp'].iloc[:i], **model, exog = df1[['humidity', 'wind_speed']].iloc[:i])\n    ucm_fitted = ucm.fit(method = 'powell', disp = False)\n\n    forecast = ucm_fitted.forecast(exog = df1[['humidity', 'wind_speed']].iloc[i])\n\n    predictions = pd.concat([predictions, forecast])\n    \nmae_ucm = (df1['meantemp'].iloc[1100:] - predictions.iloc[1100:]).abs().mean()\n\nrmse_ucm = np.sqrt(  ( (df1['meantemp'].iloc[1100:] - predictions.iloc[1100:]) * (df1['meantemp'].iloc[1100:] - predictions.iloc[1100:]) ).mean() )\n\nprint('Resultados Validação - UCM')\nprint('RMSE : ' + str(rmse_ucm))\nprint('MAE : ' + str(mae_ucm))","metadata":{"execution":{"iopub.status.busy":"2022-02-21T22:39:17.268856Z","iopub.execute_input":"2022-02-21T22:39:17.269299Z","iopub.status.idle":"2022-02-21T22:45:31.975092Z","shell.execute_reply.started":"2022-02-21T22:39:17.269255Z","shell.execute_reply":"2022-02-21T22:45:31.97383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"# Comparação de Performance com uma Decision Tree\n\n- Construção de novas features para tentar fazer o modelo captar o comportamento histórico","metadata":{}},{"cell_type":"code","source":"df1['valor_t-1'] = df1['meantemp'].shift()\ndf1['valor_t-2'] = df1['meantemp'].shift(2)\ndf1['valor_t-3'] = df1['meantemp'].shift(3)\n\ndf1['diferenca_t-1'] = df1['meantemp'].shift().diff()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-22T03:02:41.830957Z","iopub.execute_input":"2022-02-22T03:02:41.831236Z","iopub.status.idle":"2022-02-22T03:02:41.842313Z","shell.execute_reply.started":"2022-02-22T03:02:41.831206Z","shell.execute_reply":"2022-02-22T03:02:41.841324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regressor.max_depth = 5\n\nfrom sklearn.model_selection import cross_val_score\nscores_rmse = cross_val_score(regressor, df1.iloc[5:,1:], df1['meantemp'].iloc[5:], cv = 50, scoring = 'neg_mean_squared_error')\nrmse_decision_tree = np.sqrt(abs(scores_rmse.mean()))\n\nscores_mae = cross_val_score(regressor, df1.iloc[5:,1:], df1['meantemp'].iloc[5:], cv = 50, scoring = 'neg_mean_absolute_error')\nmae_decision_tree = abs(scores_mae.mean())\n\nprint('Resultados Validação - Decision Tree')\nprint('RMSE : ' + str(rmse_decision_tree))\nprint('MAE : ' + str(mae_decision_tree))","metadata":{"execution":{"iopub.status.busy":"2022-02-22T03:04:46.839396Z","iopub.execute_input":"2022-02-22T03:04:46.839618Z","iopub.status.idle":"2022-02-22T03:04:48.074826Z","shell.execute_reply.started":"2022-02-22T03:04:46.839596Z","shell.execute_reply":"2022-02-22T03:04:48.073937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (80, 60))\n\ntree.plot_tree(decision_tree = regressor, feature_names = df1.iloc[5:,1:].columns)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T21:55:37.996359Z","iopub.execute_input":"2022-02-21T21:55:37.996746Z","iopub.status.idle":"2022-02-21T21:55:42.663342Z","shell.execute_reply.started":"2022-02-21T21:55:37.996711Z","shell.execute_reply":"2022-02-21T21:55:42.66252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Referencias\n\nSobre estacionariedade em séries temporais:\n\n    Marcos Lopez de Prado - Advances in Financial Machine Learning\n\n\nSobre UCM:\n\n    https://www.youtube.com/watch?v=v5ijNXvlC5A - Modern Time Series Analysis | SciPy 2019 Tutorial | Aileen Nielsen\n\n    Pelagatti, Matteo M - Time series modelling with unobserved components\n\nSobre estimação multiplas sazonalidade utilizando componentes trigonometricos:\n\n    https://www.statsmodels.org/devel/examples/notebooks/generated/statespace_seasonal.html\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T20:17:51.61668Z","iopub.execute_input":"2022-02-21T20:17:51.617878Z","iopub.status.idle":"2022-02-21T20:17:51.622292Z","shell.execute_reply.started":"2022-02-21T20:17:51.617829Z","shell.execute_reply":"2022-02-21T20:17:51.621372Z"}}}]}